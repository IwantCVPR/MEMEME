\documentclass[10pt,conference,a4paper]{IEEEtran}
% *** CITATION PACKAGES ***
%
\ifCLASSOPTIONcompsoc
% IEEE Computer Society needs nocompress option
% requires cite.sty v4.0 or later (November 2003)
\usepackage[nocompress]{cite}
\else
% normal IEEE
\usepackage{cite}
\fi

% *** GRAPHICS RELATED PACKAGES ***
%
\usepackage{subfigure} % add by kk
\usepackage{float} % add by kk
\usepackage{CJK} % add by kk
\usepackage{amsmath} % add by kk
\usepackage{amssymb} % add by kk
\usepackage{longtable} % add by kk
\usepackage{multirow} % add by kk
\usepackage{array} % add by kk
\usepackage{chngpage} %  add by kk
\usepackage{hyperref} % add by kk
\usepackage{mathrsfs} % add by kk

\ifCLASSINFOpdf
\usepackage[pdftex]{graphicx}
% declare the path(s) where your graphic files are
\graphicspath{{../pdf/}{../jpeg/}}
% and their extensions so you won't have to specify these with
% every instance of \includegraphics
\DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
% or other class option (dvipsone, dvipdf, if not using dvips). graphicx
% will default to the driver specified in the system graphics.cfg if no
% driver is specified.
\usepackage[dvips]{graphicx}
% declare the path(s) where your graphic files are
\graphicspath{{../eps/}}
% and their extensions so you won't have to specify these with
% every instance of \includegraphics
\DeclareGraphicsExtensions{.eps}
\fi
% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}



\begin{document}
	\title{Automatic Mathematical Expression Alignment and Recognition System}
	% author names and affiliations
	% use a multiple column layout for up to three different
	% affiliations
	\author{
		\IEEEauthorblockN{kk$^{1}$}
		\IEEEauthorblockA{
			$^{1}$ National Laboratory of Pattern Recognition, \\
			Institute of Automation, Chinese Academy of Sciences, Beijing, China \\
			Email: \{kk\}@nlpr.ia.ac.cn \\
		}
	}
	%\footnote{National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences}
	% make the title area
	\maketitle
	% As a general rule, do not put math, special symbols or citations
	% in the abstract
	\begin{abstract}
		Most previous mathematical expression recognition systems are built by rule-based methods. In this paper, we proposed a novel method to learn to adjust distorted mathematical expressions and output structural result in \LaTeX\ form ... 
	\end{abstract}
	
	\IEEEpeerreviewmaketitle
	\section{Introduction}
	Mathematical Expression (ME) plays a role in scientific area. Automatic ME recognition has been studied since 1960s and thrived from 1980s to recent years [survey]. A typical ME recognition system usually contains three parts: mathematical symbol (MS) segmentation, mathematical symbol recognition and structural analysis. For previous studies on ME recognition, most of the research focused on scanned document where background contains little noise and this assists MS segmentation to perform well. However, as the popularity of using mobile devices grows, we tend to deal with camera-taken images instead of scanned ones and this brings more challenges for Optical Character Recognition (OCR) area. Segmentation 
	
	
	recognition has been studied for a long time. 
	Review ME recognition methods and point out the problems ...
		
	Review CNN ...
		
	In this paper, our contribution mainly falls into two aspects: 1.Proposed an automatic alignment and recognition system; 2. Build a new benchmark composed of distorted ME images.
		
	The remainder of this paper begins with ... We then ... We then report the results ...
		
	\section{Related Work}
	...
	
	\section{Proposed Method}
	% Before giving the network structure, we should give a block diagram of ME image processing, with the CNN as a block in it. Explain every step in the processing flow.
	% The overview part needs substantial extension. It should give a complete view of the method to the readers.
	\subsection{Overview}
	\begin{figure*}
		\centering
		\includegraphics[scale=0.3]{images/stn-densebox-pipline.eps}
	\end{figure*}
	Our system mainly contains three parts as shown in Fig.x. The ME alignment part is designed to adjust the ME in image to be horizontally centered. The following MS Recognition part takes in the adjusted ME and outputs the bounding box and category for each symbol. 
	\subsection{Automatic alignment}
	We borrow some ideas in Spatial Transformer Network to perform the ME alignment. In [stn], the network takes the category label, which can be regarded as a $1 \times 1$ matrix, as the supervised information for each image and the transformation parameters are learned in an unsupervised way. While considering that the afterwards fully convolution network for MS detection and recognition takes a $n \times n$ matrix as the supervised message and the label containing spatial information is set on condition that the ME has already been properly aligned, it is essential to learn the transformation in a supervised way and pretrain the alignment network.
	
	The STN uses a $2 \times 3$ transformation matrix to represent translation, rotation, scale and shear. One natural way to directly learn the $2 \times 3$ matrix, and if we only consider translation and rotation, the transformation matrix $T$ can be represented as 
	\begin{equation}
		T = 
		\begin{bmatrix}
		\cos\theta & -\sin\theta & x\\ 
		\sin\theta & \cos\theta & y
		\end{bmatrix}
	\end{equation}
	However, there are two problems need to be dealt with. The first one is that dimensions of $x, y, \sin(\theta), \cos(\theta)$ are not unified and the loss may be small enough for translation parameters but far from ideal for rotation ones. The second problem is that the network is required to regress complicated nonlinear functions like $\sin, \cos$ or compound ones, and it is not an easy task. Consequently, we split $T$ into three matrices $T_1, T_2, T_3$ each of which represents translation, rotation and scale, respectively.
	\begin{equation}
		T_1 = 
		\begin{bmatrix}
		1 & 0 & x\\
		0 & 1 & y\\
		0 & 0 & 1
		\end{bmatrix}
	\end{equation}
	\begin{equation}
		T_2 = 
		\begin{bmatrix}
		\cos\theta & -\sin\theta & 0\\
		\sin\theta & \cos\theta & 0\\
		0 & 0 & 1
		\end{bmatrix}
	\end{equation}
	\begin{equation}
	T_3 = 
	\begin{bmatrix}
	s & 0 & 0\\
	0 & s & 0\\
	0 & 0 & 1
	\end{bmatrix}
	\end{equation}
%	\begin{equation}
%	T_1 = 
%	\begin{bmatrix}
%	1 & 0 & 0\\
%	0 & 1 & 0\\
%	x & y & 1
%	\end{bmatrix}
%	\end{equation}
%	\begin{equation}
%	T_2 = 
%	\begin{bmatrix}
%	\cos\theta & \sin\theta & 0\\
%	-\sin\theta & \cos\theta & 0\\
%	0 & 0 & 1
%	\end{bmatrix}
%	\end{equation}
%	\begin{equation}
%	T_3 = 
%	\begin{bmatrix}
%	s & 0 & 0\\
%	0 & s & 0\\
%	0 & 0 & 1
%	\end{bmatrix}
%	\end{equation}
	In the training stage, we first unify the mean value and variation of ground truth $x, y, \theta, s$ into $x', y', \theta', s'$ and regress $x', y', \theta', s'$ by a multi-task structure shown in Fig.[Alignment Network]. And in the test stage, we first convert unified transformation parameters back to their own statistic and then integrate $T_1, T_2, T_3$ into $T$ by
	\begin{equation}
		T = T_1 \cdot T_2 \cdot T_3
	\end{equation}
	and finally remove the last row of $T$ to get the $2 \times 3$ transformation matrix for $Grid Generator$ and $Sampler$ introduced in [stn].
		
	\subsection{Mathematical symbol detection and recognition}	
    We adopt the method for MS detection and recognition in [context-aware-ME]. Compared with [context-aware-ME], we consider more complicated MSs including square root.
    Before training the network, we pre-process the label of square root. 
    The bounding box of a square root is shown in Fig.[sqrt]
	\subsection{Joint training}
	Differentiable of alignment network
	\subsection{Structural analysis}
	...
	\section{Experiments}
	...
	\subsection{Implementation details}
	...
	\subsection{Databases}
	...
	\subsubsection{Infty}
	...
	\subsubsection{Real-life Images}
	...
	\subsection{Compared with skew correction}
	...
	\subsection{Effectiveness of split transformation matrix}
	...
	\subsection{Effectiveness of joint-training}
	No joint-training
	Joint-training:
		1. Continue supervising transformation
		2. Training transformation in unsupervised way
	
	
	
	\section{Conclusion}
	...
	
	%\bibliographystyle{IEEEtran}
	%\bibliography{ref}
\end{document}


